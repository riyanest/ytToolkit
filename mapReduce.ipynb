# MapReduce (6)


Text="""MapReduce is a processing technique and a program model for distributed computing
based on java. The MapReduce algorithm contains two important tasks, namely Map and Reduce.
Map takes a set of data and converts it into another set of data, where individual elements are
broken down into tuples (key/value pairs). Secondly, reduce task, which takes the output from a
map as an input and combines those data tuples into a smallerset of tuples. As the sequence of the
name MapReduce implies, the reduce task is always performed after the map job.
Map stage − The map or mapper’s job is to process the input data. Generally, the
input data isin the form of file or directory and is stored in the Hadoop file system
(HDFS). The input file is passed to the mapper function line by line. The mapper
processesthe data and creates several small chunks of data.
Reduce stage − This stage is the combination of the Shuffle stage and the Reduce
stage. The Reducer’s job is to process the data that comes from the mapper. After
processing, it produces anew set of output, which will be stored in the HDFS.
"""
# Cleaning text and lower casing all words
for char in '-.,\n':
  Text=Text.replace(char,' ')
Text = Text.lower()
# split returns a list of words delimited by sequences of whitespace (including tabs, newlines, etc, like re's \s)
word_list = Text.split()
from collections import Counter
Counter(word_list).most_common()
# Initializing Dictionary
d = {}
# counting number of times each word comes up in list of words (in dictionary)
for word in word_list:
  d[word] = d.get(word, 0) + 1
#reverse the key and values so they can be sorted using
word_freq = []
for key, value in d.items():
  word_freq.append((value, key))
word_freq.sort(reverse=True)
print(word_freq)
